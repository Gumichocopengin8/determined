"""
A set of utilities for managing requirements files.
- intake a directory of requirements files and build a map of dependencies to tags
- merge with a map of dependencies with versions to tags
- generate temporary requirements files from a map of dependencies to tags for backward compat
"""

import dataclasses
import os
import pathlib
import sys
from typing import Dict, List, NamedTuple, Sequence, Tuple

"""
We are defining our dependencies in an "Inverted Index"
here to allow for each of the dependencies to not be
repeated, and tagging it's usage throughout the platform.

Example:
"determined==0.29.1": ["base", "sdk"],
"dataclass_wizard": ["base"],
"fastapi>=0.95.1": ["api"],

Would yield an extra requirements field of:
{
"base": ["determined==0.29.1", "dataclass_wizard"],
"sdk": ["determined==0.29.1"],
"api": ["fastapi>=0.95.1"],
"all": ["determined==0.29.1", "dataclass_wizard", "fastapi>=0.95.1"],
}

One could then install specifically what was necessary for the SDK, API, etc
according to their needs.
"""

HardCodedReqs = Dict[str, List[str]]

REQUIREMENTS = {
    "watchfiles==0.21.0": ["backend-server"],
}


@dataclasses.dataclass()
class Dependency:
    name: str
    constraint: str
    tags: List[str]

    def key(self) -> str:
        return f"{self.name}{self.constraint}"

    @classmethod
    def from_line(cls, line: str, tags: List[str]) -> "Dependency":
        name, constraint = parse_requirement_line(line)
        return cls(name=name, constraint=constraint, tags=tags)


@dataclasses.dataclass()
class Requirements:
    dependencies: Dict[str, Dependency]

    def to_human_map_str(self) -> str:
        """Convert a requirements map to a human-readable map."""
        return format_for_hardcoding(list(self.dependencies.values()))

    def to_requirements_files(self, directory: pathlib.Path):
        return generate_requirements_files(self.dependencies, directory)

    @classmethod
    def from_requirements_file(cls, file: pathlib.Path):
        """Parse a requirements file into a Requirements object."""
        requirements_map = {}
        with open(file, "r") as f:
            for line in f:
                dep = Dependency.from_line(line, [])
                requirements_map[dep.name] = dep
        return cls(dependencies=requirements_map)


ReqFile = NamedTuple("ReqFile", [("tag", str), ("dir", str)])
req_files = [
    ReqFile("base", "./requirements.txt"),
    ReqFile("base", "./bindings/requirements.txt"),
    ReqFile("docs", "./docs/requirements.txt"),
    ReqFile("test", "./e2e_tests/tests/requirements.txt"),
]


def build_requirements_map(requirements_dir):
    """Build a map of dependencies to tags from a directory of requirements files."""
    requirements_map = {}
    for file_name in os.listdir(requirements_dir):
        if file_name.endswith("-requirements.txt"):
            tag = file_name.replace("-requirements.txt", "")
            file_path = os.path.join(requirements_dir, file_name)
            with open(file_path, "r") as file:
                for line in file:
                    dep = line.strip()
                    if dep:
                        if dep in requirements_map:
                            requirements_map[dep].add(tag)
                        else:
                            requirements_map[dep] = {tag}
    requirements_map = dict(sorted(requirements_map.items()))
    for dep, tags in requirements_map.items():
        requirements_map[dep] = sorted(list(tags))
    return requirements_map


def generate_requirements_files(requirements_map, directory: pathlib.Path):
    """Generate temporary requirements files from a map of dependencies to tags."""
    directory.mkdir(parents=True, exist_ok=True)
    for tag in set(sum(requirements_map.values(), [])):
        file_name = f"{tag}-requirements.txt"
        file_path = directory / file_name
        with open(file_path, "w") as file:
            file.write("# This file is generated by requirements.py\n")
            for dep, tags in requirements_map.items():
                if tag in tags:
                    file.write(f"{dep}\n")
    return directory


def format_for_hardcoding(dependencies: Sequence[Dependency]) -> str:
    """Format a requirements map for hardcoding into a Python file."""
    assert len(dependencies) == len(set([dep.name for dep in dependencies]))
    formatted_str = "REQUIREMENTS = {\n"
    for dep in dependencies:
        formatted_str += f'    "{dep.key()}": {dep.tags},\n'
    formatted_str += "}\n"
    return formatted_str


def merge_with_original(requirements_map, original_requirements):
    """Merge a requirements map with the original requirements."""
    merged_map = requirements_map.copy()
    for dep, tags in original_requirements.items():
        if dep in merged_map:
            merged_map[dep] = sorted(list(set(merged_map[dep] + tags)))
        else:
            merged_map[dep] = tags
    return merged_map


def parse_requirement_line(line: str) -> Tuple[str, str]:
    """parse a line from a requirements file into a dependency and version constraints
    assuming a simple fromat of <dep><contraints>
    """
    ops = {"<", ">", "=", "~"}
    for i, char in enumerate(line):
        if char in ops:
            return line[:i], line[i:]
    return line, ""


def compress_requirements(requirements_map) -> Dict[str, Dependency]:
    """compress requirements by merging constraints and tags"""
    compressed_map: Dict[str, Dependency] = {}
    for depline, tags in requirements_map.items():
        name, ver = parse_requirement_line(depline)
        dep = Dependency(name=name.strip(), constraint=ver, tags=tags)
        if dep.name in compressed_map:
            compressed_map[dep.name].tags = sorted(list(set(compressed_map[dep.name].tags + tags)))
            if not compressed_map[dep.name].constraint:
                compressed_map[dep.name].constraint = dep.constraint
        else:
            compressed_map[dep.name] = dep
    return compressed_map


def has_no_version_defined(constraint: str):
    return not any([op in constraint for op in ["<", ">", "=", "~"]])


def has_no_upper_bound(constraint: str):
    return ">=" in constraint and "<" not in constraint and "~" not in constraint


def warn_for_deps_without_version(requirements_map):
    """Warn for dependencies without a version given a requirements map."""

    for dep, _ in requirements_map.items():
        if has_no_version_defined(dep):
            print(f"[WARNING] {dep} has no version specified", file=sys.stderr)
        elif has_no_upper_bound(dep):
            print(f"[WARNING] {dep} has no upper bound specified", file=sys.stderr)


def populate_requirements_from_pip_freez(req_map: HardCodedReqs, pip_freeze_file: pathlib.Path):
    """Populate requirements from a pip freeze file."""
    reqs = Requirements({})
    for dep_line, tags in req_map.items():
        dep = Dependency.from_line(dep_line, tags)
        reqs.dependencies[dep.name] = dep
    with open(pip_freeze_file, "r") as file:
        for line in file:
            line = line.strip()
            if not line:
                continue
            dep = Dependency.from_line(line, [])
            if dep.name not in reqs.dependencies:
                continue
            existing_constraint = reqs.dependencies[dep.name].constraint
            if (
                not existing_constraint
                or has_no_version_defined(existing_constraint)
                or has_no_upper_bound(existing_constraint)
            ):
                reqs.dependencies[dep.name].constraint = dep.constraint
    return reqs.to_human_map_str()


if __name__ == "__main__":
    import argparse

    # phase 1
    # # build requirements map
    # requirements_map = build_requirements_map("./requirements")
    # # merge with original requirements
    # requirements_map = merge_with_original(requirements_map, REQUIREMENTS)
    # requirements_map = compress_requirements(REQUIREMENTS)
    # print(format_for_hardcoding(list(requirements_map.values())))
    # out = populate_requirements_from_pip_freez(
    #     REQUIREMENTS, pathlib.Path("./ciresolvedpackages.txt")
    # )
    # print(out)
    # phase 2
    parser = argparse.ArgumentParser()
    parser.add_argument("--target-dir", type=str, default="./requirements")

    args = parser.parse_args()
    warn_for_deps_without_version(REQUIREMENTS)
    output_dir = generate_requirements_files(REQUIREMENTS, pathlib.Path(args.target_dir))
    print(f"Requirements files generated in {output_dir}")
    for file_name in os.listdir(output_dir):
        print(file_name)
